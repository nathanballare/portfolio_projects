{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871ecece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f486c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo de texto\n",
    "text = open('luladiscursos.txt', \"r\", encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a2101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte o texto em um tensor de caracteres\n",
    "chars = tf.strings.unicode_decode(text, input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f212b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62abfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7102f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54522cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[50, 51, 52, 53, 54, 55, 56], [73, 74, 75]]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ac6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ffacca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad578bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1f1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3da75117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(103855,), dtype=int64, numpy=array([ 1, 28, 58, ..., 50, 53, 64], dtype=int64)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a36110ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4209e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "D\n",
      "i\n",
      "s\n",
      "c\n",
      "u\n",
      "r\n",
      "s\n",
      "o\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28ad6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2abadc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'\\n' b'D' b'i' b's' b'c' b'u' b'r' b's' b'o' b' ' b'1' b':' b' ' b'\\n'\n",
      " b'Q' b'u' b'e' b'r' b'o' b' ' b'r' b'e' b'i' b't' b'e' b'r' b'a' b'r'\n",
      " b' ' b'a' b' ' b'i' b'm' b'p' b'o' b'r' b't' b'\\xc3\\xa2' b'n' b'c' b'i'\n",
      " b'a' b' ' b'd' b'a' b' ' b'm' b'u' b'd' b'a' b'n' b'\\xc3\\xa7' b'a' b' '\n",
      " b'p' b'a' b'r' b'a' b' ' b't' b'o' b'd' b'o' b's' b' ' b'o' b's' b' '\n",
      " b'c' b'i' b'd' b'a' b'd' b'\\xc3\\xa3' b'o' b's' b' ' b'd' b'o' b' ' b'B'\n",
      " b'r' b'a' b's' b'i' b'l' b'.' b' ' b'\\xc3\\x89' b' ' b'h' b'o' b'r' b'a'\n",
      " b' ' b'd' b'e' b' ' b't' b'r' b'a'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f67c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\nDiscurso 1: \\nQuero reiterar a import\\xc3\\xa2ncia da mudan\\xc3\\xa7a para todos os cidad\\xc3\\xa3os do Brasil. \\xc3\\x89 hora de tra'\n",
      "b'nsformar o Brasil em uma na\\xc3\\xa7\\xc3\\xa3o soberana e justa. Mudaremos com coragem e humildade, cientes de que \\xc3\\xa9 '\n",
      "b'um processo gradual, baseado no di\\xc3\\xa1logo e na negocia\\xc3\\xa7\\xc3\\xa3o.\\n\\nO Brasil \\xc3\\xa9 complexo, com quase 175 milh\\xc3\\xb5es '\n",
      "b'de habitantes, e n\\xc3\\xa3o podemos permitir que ele siga sem um verdadeiro projeto de desenvolvimento nacio'\n",
      "b'nal. Precisamos exercer a paci\\xc3\\xaancia e a perseveran\\xc3\\xa7a, sem atropelos, plantando \\xc3\\xa1rvores antes de colhe'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f73863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8dcc3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29e290ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6d780af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'\\nDiscurso 1: \\nQuero reiterar a import\\xc3\\xa2ncia da mudan\\xc3\\xa7a para todos os cidad\\xc3\\xa3os do Brasil. \\xc3\\x89 hora de tr'\n",
      "Target: b'Discurso 1: \\nQuero reiterar a import\\xc3\\xa2ncia da mudan\\xc3\\xa7a para todos os cidad\\xc3\\xa3os do Brasil. \\xc3\\x89 hora de tra'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e962b90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(256, 100), dtype=tf.int64, name=None), TensorSpec(shape=(256, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurando os lotes de treinamento\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05f119da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 1024\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5558628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08936c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22caf6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 100, 97) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "622e2055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  99328     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  62939136  \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  397409    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63435873 (241.99 MB)\n",
      "Trainable params: 63435873 (241.99 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Verificando o resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab492916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10c6b370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74, 63,  7, 27, 16, 32, 27, 84, 76, 84, 78, 96, 86, 20, 35, 86,  6,\n",
       "       78, 91, 62, 85, 71, 79, 74, 95, 71, 37,  0, 63, 28, 32, 21, 91, 46,\n",
       "       17, 14, 48, 33, 46, 60,  8, 66, 33, 80, 41,  2, 63, 37, 86, 91, 89,\n",
       "       18, 18, 37, 54,  4, 89, 40, 76,  1, 61, 54, 85,  0, 63, 20, 95, 29,\n",
       "       10, 18, 73, 13, 48, 25, 41, 43, 71, 12, 48, 40, 69, 74, 34, 53, 91,\n",
       "       16, 84, 25, 45, 47, 34, 38,  8, 39, 51, 96, 76, 40, 68, 17],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "747c4871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'buscamos a compaix\\xc3\\xa3o dos pa\\xc3\\xadses ricos, mas sim solu\\xc3\\xa7\\xc3\\xb5es estruturais que fa\\xc3\\xa7am parte de uma mudan\\xc3\\xa7a g'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'yn(C4HC\\xc3\\xa7\\xc2\\xaa\\xc3\\xa7\\xc3\\x89\\xe2\\x80\\x9d\\xc3\\xaa8K\\xc3\\xaa%\\xc3\\x89\\xc3\\xb6m\\xc3\\xa9v\\xc3\\x8dy\\xe2\\x80\\x9cvM[UNK]nDH9\\xc3\\xb6V52YIVk)qI\\xc3\\xa0Q nM\\xc3\\xaa\\xc3\\xb6\\xc3\\xb466Me\"\\xc3\\xb4P\\xc2\\xaa\\nle\\xc3\\xa9[UNK]n8\\xe2\\x80\\x9cE-6x1YAQSv0YPtyJd\\xc3\\xb64\\xc3\\xa7AUXJN)Ob\\xe2\\x80\\x9d\\xc2\\xaaPs5'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0513f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0adefb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (256, 100, 97)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.575513, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7ddb80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.07782"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecbd3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # Defina a taxa de aprendizado desejada\n",
    "model.compile(optimizer=optimizer, loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e8d26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = 'C:\\\\Users\\\\natha\\\\anaconda3\\\\Text Generation with GAN_1'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2431fa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 395s 100s/step - loss: 4.5392 - accuracy: 0.1383\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 354s 89s/step - loss: 4.3612 - accuracy: 0.1568\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 353s 89s/step - loss: 3.9859 - accuracy: 0.1436\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 351s 89s/step - loss: 4.0081 - accuracy: 0.1797\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 361s 91s/step - loss: 4.0015 - accuracy: 0.2297\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 580s 164s/step - loss: 3.8416 - accuracy: 0.1986\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 403s 99s/step - loss: 3.4859 - accuracy: 0.1385\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 353s 89s/step - loss: 3.3396 - accuracy: 0.1292\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 358s 89s/step - loss: 3.1629 - accuracy: 0.1950\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 365s 92s/step - loss: 3.1445 - accuracy: 0.1475\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 354s 88s/step - loss: 3.1268 - accuracy: 0.1456\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 356s 89s/step - loss: 3.0816 - accuracy: 0.1495\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 350s 88s/step - loss: 3.0412 - accuracy: 0.2059\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 357s 90s/step - loss: 3.0243 - accuracy: 0.2360\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 363s 91s/step - loss: 3.0054 - accuracy: 0.2354\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 350s 88s/step - loss: 2.9782 - accuracy: 0.2363\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 351s 87s/step - loss: 2.9541 - accuracy: 0.2278\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 365s 93s/step - loss: 2.9323 - accuracy: 0.2195\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 354s 89s/step - loss: 2.9082 - accuracy: 0.2306\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 359s 90s/step - loss: 2.8827 - accuracy: 0.2411\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 356s 90s/step - loss: 2.8580 - accuracy: 0.2433\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 357s 91s/step - loss: 2.8327 - accuracy: 0.2444\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 359s 91s/step - loss: 2.8068 - accuracy: 0.2457\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 361s 91s/step - loss: 2.7812 - accuracy: 0.2480\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 365s 92s/step - loss: 2.7552 - accuracy: 0.2567\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 351s 89s/step - loss: 2.7303 - accuracy: 0.2596\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 355s 90s/step - loss: 2.7052 - accuracy: 0.2605\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 394s 101s/step - loss: 2.6810 - accuracy: 0.2620\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 468s 118s/step - loss: 2.6586 - accuracy: 0.2644\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 484s 126s/step - loss: 2.6365 - accuracy: 0.2718\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 367s 91s/step - loss: 2.6146 - accuracy: 0.2736\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 353s 89s/step - loss: 2.5957 - accuracy: 0.2740\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 360s 91s/step - loss: 2.5775 - accuracy: 0.2763\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 356s 90s/step - loss: 2.5598 - accuracy: 0.2787\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 376s 97s/step - loss: 2.5423 - accuracy: 0.2812\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 834s 98s/step - loss: 2.5264 - accuracy: 0.2812\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 371s 92s/step - loss: 2.5102 - accuracy: 0.2818\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 381s 96s/step - loss: 2.4954 - accuracy: 0.2833\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 371s 95s/step - loss: 2.4812 - accuracy: 0.2846\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 386s 97s/step - loss: 2.4667 - accuracy: 0.2866\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 376s 94s/step - loss: 2.4532 - accuracy: 0.2925\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 4319s 1408s/step - loss: 2.4403 - accuracy: 0.2967\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 432s 105s/step - loss: 2.4267 - accuracy: 0.3005\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 426s 109s/step - loss: 2.4148 - accuracy: 0.3041\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 400s 101s/step - loss: 2.4021 - accuracy: 0.3124\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 405s 101s/step - loss: 2.3905 - accuracy: 0.3153\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 367s 92s/step - loss: 2.3792 - accuracy: 0.3176\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 376s 96s/step - loss: 2.3684 - accuracy: 0.3188\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 361s 91s/step - loss: 2.3581 - accuracy: 0.3203\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 357s 90s/step - loss: 2.3481 - accuracy: 0.3216\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 11321s 3744s/step - loss: 2.3382 - accuracy: 0.3235\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 381s 95s/step - loss: 2.3286 - accuracy: 0.3247\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 368s 93s/step - loss: 2.3197 - accuracy: 0.3263\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 365s 92s/step - loss: 2.3101 - accuracy: 0.3292\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 366s 92s/step - loss: 2.3018 - accuracy: 0.3308\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 363s 92s/step - loss: 2.2938 - accuracy: 0.3328\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 370s 94s/step - loss: 2.2864 - accuracy: 0.3334\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 368s 94s/step - loss: 2.2789 - accuracy: 0.3361\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 362s 90s/step - loss: 2.2709 - accuracy: 0.3382\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 363s 92s/step - loss: 2.2640 - accuracy: 0.3376\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 373s 92s/step - loss: 2.2568 - accuracy: 0.3406\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 387s 99s/step - loss: 2.2501 - accuracy: 0.3412\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 371s 94s/step - loss: 2.2438 - accuracy: 0.3414\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 366s 92s/step - loss: 2.2372 - accuracy: 0.3456\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 375s 94s/step - loss: 2.2321 - accuracy: 0.3445\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 371s 94s/step - loss: 2.2259 - accuracy: 0.3472\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 358s 90s/step - loss: 2.2194 - accuracy: 0.3481\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 368s 94s/step - loss: 2.2143 - accuracy: 0.3509\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 363s 92s/step - loss: 2.2091 - accuracy: 0.3509\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 372s 95s/step - loss: 2.2030 - accuracy: 0.3521\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 361s 91s/step - loss: 2.1980 - accuracy: 0.3524\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 369s 94s/step - loss: 2.1924 - accuracy: 0.3538\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 367s 93s/step - loss: 2.1878 - accuracy: 0.3547\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 375s 96s/step - loss: 2.1823 - accuracy: 0.3542\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 364s 92s/step - loss: 2.1775 - accuracy: 0.3563\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 348s 88s/step - loss: 2.1726 - accuracy: 0.3561\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 351s 88s/step - loss: 2.1678 - accuracy: 0.3576\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 353s 90s/step - loss: 2.1635 - accuracy: 0.3577\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 351s 89s/step - loss: 2.1576 - accuracy: 0.3592\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 360s 92s/step - loss: 2.1538 - accuracy: 0.3598\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 357s 89s/step - loss: 2.1490 - accuracy: 0.3603\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 350s 88s/step - loss: 2.1466 - accuracy: 0.3604\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 351s 88s/step - loss: 2.1408 - accuracy: 0.3624\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 347s 87s/step - loss: 2.1365 - accuracy: 0.3632\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 364s 92s/step - loss: 2.1320 - accuracy: 0.3649\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 353s 88s/step - loss: 2.1272 - accuracy: 0.3660\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 363s 90s/step - loss: 2.1233 - accuracy: 0.3671\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 367s 90s/step - loss: 2.1178 - accuracy: 0.3683\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 360s 91s/step - loss: 2.1139 - accuracy: 0.3706\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 359s 91s/step - loss: 2.1090 - accuracy: 0.3723\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 376s 94s/step - loss: 2.1037 - accuracy: 0.3721\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 362s 91s/step - loss: 2.0991 - accuracy: 0.3741\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 372s 95s/step - loss: 2.0958 - accuracy: 0.3753\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 360s 90s/step - loss: 2.0902 - accuracy: 0.3759\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 361s 91s/step - loss: 2.0855 - accuracy: 0.3790\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 364s 91s/step - loss: 2.0814 - accuracy: 0.3797\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 360s 91s/step - loss: 2.0775 - accuracy: 0.3798\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 368s 93s/step - loss: 2.0723 - accuracy: 0.3827\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 354s 89s/step - loss: 2.0678 - accuracy: 0.3844\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 366s 93s/step - loss: 2.0620 - accuracy: 0.3872\n"
     ]
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "EPOCHS = 100\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4fda48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 371s 94s/step - loss: 2.0578 - accuracy: 0.3876\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 369s 94s/step - loss: 2.0532 - accuracy: 0.3880\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 359s 90s/step - loss: 2.0478 - accuracy: 0.3903\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 371s 92s/step - loss: 2.0427 - accuracy: 0.3919\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 367s 92s/step - loss: 2.0376 - accuracy: 0.3929\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 366s 92s/step - loss: 2.0340 - accuracy: 0.3942\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 365s 93s/step - loss: 2.0289 - accuracy: 0.3959\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 361s 90s/step - loss: 2.0244 - accuracy: 0.3965\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 362s 91s/step - loss: 2.0209 - accuracy: 0.3977\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 370s 94s/step - loss: 2.0166 - accuracy: 0.3999\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 363s 92s/step - loss: 2.0100 - accuracy: 0.4012\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 361s 92s/step - loss: 2.0047 - accuracy: 0.4035\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 356s 90s/step - loss: 1.9986 - accuracy: 0.4053\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 358s 90s/step - loss: 1.9941 - accuracy: 0.4048\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 360s 91s/step - loss: 1.9906 - accuracy: 0.4068\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 367s 93s/step - loss: 1.9845 - accuracy: 0.4091\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 362s 92s/step - loss: 1.9776 - accuracy: 0.4095\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 395s 100s/step - loss: 1.9725 - accuracy: 0.4126\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 451s 115s/step - loss: 1.9672 - accuracy: 0.4137\n",
      "Epoch 20/100\n"
     ]
    }
   ],
   "source": [
    "# Carregue o modelo treinado\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9991ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['DISCURSO:', 'DISCURSO:', 'DISCURSO:', 'DISCURSO:', 'DISCURSO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['DISCURSO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3cab13",
   "metadata": {},
   "source": [
    "Gráfico de Precisão: Se estiver treinando um modelo de classificação, você pode adicionar um gráfico de precisão da mesma maneira que o gráfico de perda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Função para plotar o gráfico de precisão sobre os modelos treinados\n",
    "def plot_accuracy(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Precisão', marker='o', linestyle='-')\n",
    "    plt.title('Precisão do Modelo ao Longo das Épocas')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Precisão')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b2223",
   "metadata": {},
   "source": [
    "Gráfico de Perda: Isso já está incluído no treinamento, mas você pode personalizá-lo para torná-lo mais visualmente atraente. Você pode usar bibliotecas de plotagem, como Matplotlib ou Seaborn, para criar um gráfico de linha que mostra a perda ao longo das épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dcdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Perda', marker='o', linestyle='-')\n",
    "    plt.title('Perda do Modelo ao Longo das Épocas')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2126a5",
   "metadata": {},
   "source": [
    "Comparação de Modelos: Se você deseja comparar o desempenho de diferentes modelos ou configurações de hiperparâmetros, pode criar um gráfico de barras que mostra as métricas (perda, precisão, etc.) de cada modelo lado a lado. Aqui está um exemplo simples usando Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d514222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = ['Modelo 1', 'Modelo 2', 'Modelo 3']\n",
    "loss = [0.5, 0.4, 0.6]\n",
    "accuracy = [0.8, 0.85, 0.75]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "width = 0.35\n",
    "x = range(len(models))\n",
    "\n",
    "bar1 = ax.bar(x, loss, width, label='Perda')\n",
    "bar2 = ax.bar([i + width for i in x], accuracy, width, label='Precisão')\n",
    "\n",
    "ax.set_xlabel('Modelos')\n",
    "ax.set_ylabel('Métricas')\n",
    "ax.set_title('Comparação de Modelos')\n",
    "ax.set_xticks([i + width / 2 for i in x])\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c29c0a",
   "metadata": {},
   "source": [
    "Gráfico de Evolução do Texto Gerado: Se você estiver gerando texto com o modelo treinado, pode criar um gráfico que mostre a evolução do texto gerado ao longo das épocas. Por exemplo, você pode escolher algumas épocas intermediárias e gerar texto com o modelo em cada uma delas, depois plotar o texto gerado em um gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Épocas escolhidas\n",
    "epochs = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "# Texto gerado em cada época\n",
    "generated_text = [\n",
    "    \"Texto gerado na época 10\",\n",
    "    \"Texto gerado na época 20\",\n",
    "    \"Texto gerado na época 30\",\n",
    "    \"Texto gerado na época 40\",\n",
    "    \"Texto gerado na época 50\",\n",
    "    \"Texto gerado na época 60\",\n",
    "    \"Texto gerado na época 70\",\n",
    "    \"Texto gerado na época 80\",\n",
    "    \"Texto gerado na época 90\",\n",
    "    \"Texto gerado na época 100\"\n",
    "]\n",
    "\n",
    "# Crie um gráfico de linha para mostrar a evolução do texto gerado\n",
    "plt.figure(figsize=(11, 10))\n",
    "plt.plot(epochs, generated_text, marker='o', linestyle='-')\n",
    "plt.title('Evolução do Texto Gerado ao Longo das Épocas')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Texto Gerado')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295701ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c697e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
